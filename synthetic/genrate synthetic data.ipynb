{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import errno\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(n_instances, n_features, n_informative, n_redundant, n_classes, class_sep=1.0, n_clusters=1, seed=0):\n",
    "    \"Generate synthetic data.\"\n",
    "    X, y = datasets.make_classification(\n",
    "        n_samples=n_instances,                  # The number of samples\n",
    "        n_features=n_features,                  # The total number of features.\n",
    "        n_informative=n_informative,   # The number of informative features\n",
    "        n_redundant=n_redundant,                          # No redundant features\n",
    "        n_repeated=0,                           # No duplicated features\n",
    "        n_classes=n_classes,                    # The number of classes\n",
    "        n_clusters_per_class=n_clusters,        # The number of clusters per class.\n",
    "        weights=None,                           # balanced classes\n",
    "        flip_y=0,                               # The fraction of samples whose class are randomly exchanged\n",
    "        class_sep=class_sep,                          # Larger values spread out the clusters/classes and make the classification task easier.\n",
    "        scale=1.0,                              # No scale\n",
    "        shuffle=True,                           # Shuffle the samples and the features.\n",
    "        random_state=seed)\n",
    "    \n",
    "    # attach labels to data\n",
    "    data = np.column_stack((X,y))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start generating synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = generate(\n",
    "    n_instances=10000,\n",
    "    n_features=10,\n",
    "    n_informative=10,\n",
    "    n_redundant=0,\n",
    "    n_classes=2,\n",
    "    class_sep=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WRITE_PATH=\"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/easy_informative_10/\"\n",
    "try:\n",
    "    os.makedirs(WRITE_PATH)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise\n",
    "np.savetxt(WRITE_PATH+\"data.csv\", data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA = \"difficult_informative_10\"\n",
    "PATH = \"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/rest.csv\".format(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    PATH, \n",
    "    header=None,\n",
    "    sep=',',  #'\\s+'\n",
    "    skiprows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/virtualenv/tensorflow/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "target_index = data.columns[-1]\n",
    "split = StratifiedShuffleSplit(n_splits=1, train_size=2000, random_state=0)\n",
    "for train_index, _ in split.split(data, data[target_index]):\n",
    "    train_set = data.loc[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set.to_csv(\"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/train_2000.csv\".format(DATA),\n",
    "                header=False,\n",
    "                index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
