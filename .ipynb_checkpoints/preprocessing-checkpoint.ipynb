{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"easy_informative_10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/data.csv\".format(DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    PATH, \n",
    "    header=None,\n",
    "    sep=',',  #'\\s+'\n",
    "    skiprows=None)\n",
    "#     dtype=np.float32,\n",
    "#     na_values=[\"?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic data information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Convert categorical variable to dummy variable <br/>\n",
    "Delete columns <br/>\n",
    "Extract binary classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create dummy variables for categorical variables\n",
    "# seismic_dummies = pd.get_dummies(data[0])\n",
    "# seismoacoustic_dummies = pd.get_dummies(data[1])\n",
    "# shift_dummies = pd.get_dummies(data[2])\n",
    "# ghazard_dummies = pd.get_dummies(data[7])\n",
    "# # delete original categorical variables\n",
    "# data.drop([0, 1, 2, 7], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = data[(data[40] == 1) | (data[40] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat([seismic_dummies, seismoacoustic_dummies, shift_dummies, ghazard_dummies, data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop([\"Study\", \"Run\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[10] = data[10].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dummies = pd.get_dummies(data[0])\n",
    "# data.drop(0, axis=1, inplace=True)\n",
    "# data = pd.concat([dummies, data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(\"/home/ypen260/gitrepos/project_activationfunction/generalisation/uci_data/magic04_new/data.csv\",\n",
    "#                 header=False,\n",
    "#                 index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Stratified sampling to create test set and the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/data.csv\".format(DATA), \n",
    "    header=None,\n",
    "    sep=',',\n",
    "    skiprows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_index = data.columns[-1]\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "for rest_index, test_index in split.split(data, data[target_index]):\n",
    "    rest_set = data.loc[rest_index]\n",
    "    test_set = data.loc[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_set.to_csv(\"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/rest.csv\".format(DATA),\n",
    "                header=False,\n",
    "                index=False)\n",
    "test_set.to_csv(\"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/test.csv\".format(DATA),\n",
    "                header=False,\n",
    "                index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training set and unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_data = pd.read_csv(\n",
    "        \"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/rest.csv\".format(DATA), \n",
    "        header=None,\n",
    "        sep=',',\n",
    "        skiprows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split remaining data into training data and unlabelled data\n",
    "target_index = remaining_data.columns[-1]\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "for unlabelled_index, train_index in split.split(remaining_data, remaining_data[target_index]):\n",
    "    unlabelled = remaining_data.loc[unlabelled_index]\n",
    "    train_set = remaining_data.loc[train_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all the labels for unlabelled data\n",
    "target_index = remaining_data.columns[-1]\n",
    "unlabelled.drop(target_index, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv(\"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/train.csv\".format(DATA),\n",
    "                header=False,\n",
    "                index=False)\n",
    "unlabelled.to_csv(\"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/unlabelled.csv\".format(DATA),\n",
    "                header=False,\n",
    "                index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training and validation sets for pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/train.csv\".format(DATA)\n",
    "unlabelled_path = \"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/unlabelled.csv\".format(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(train_path, header=None)\n",
    "unlabelled = pd.read_csv(unlabelled_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_index = remaining_data.columns[-1]\n",
    "train_set.drop(target_index, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train and unlabelled data\n",
    "combined = pd.concat([train_set, unlabelled], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split combined into unlabelled_train and unlabelled_val\n",
    "unlabelled_train, unlabelled_val = train_test_split(combined, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_train_path = \"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/unlabelled_train.csv\".format(DATA)\n",
    "unlabelled_val_path = \"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/unlabelled_val.csv\".format(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_train.to_csv(unlabelled_train_path,\n",
    "                header=False,\n",
    "                index=False)\n",
    "unlabelled_val.to_csv(unlabelled_val_path,\n",
    "                header=False,\n",
    "                index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation sets for the supervised pretraining\n",
    "pre_train = utils.get_pretrain_data(unlabelled_train_path, seed=0)\n",
    "pre_val = utils.get_pretrain_data(unlabelled_val_path, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 2*unlabelled_train.shape[0] == pre_train.shape[0]\n",
    "assert 2*unlabelled_val.shape[0] == pre_val.shape[0]\n",
    "assert unlabelled_train.shape[1]+1 == pre_train.shape[1]\n",
    "assert unlabelled_val.shape[1]+1 == pre_val.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/pre_train.csv\".format(DATA), pre_train, delimiter=\",\")\n",
    "np.savetxt(\"/home/alex/gitrepos/project_activation_function/generalisation/synthetic/{}/pre_val.csv\".format(DATA), pre_val, delimiter=\",\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
